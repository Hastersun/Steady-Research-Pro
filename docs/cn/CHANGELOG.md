# Changelog

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [1.2.0] - 2025-11-03

### Added
- ğŸŒ“ **Dark Mode æ”¯æŒ** - å®Œæ•´çš„æ·±è‰²æ¨¡å¼åŠŸèƒ½
  - åˆ›å»º `ThemeToggle` React ç»„ä»¶å®ç°ä¸»é¢˜åˆ‡æ¢
  - æ·»åŠ é˜²é—ªçƒè„šæœ¬ï¼Œé¡µé¢åŠ è½½æ—¶æ— é—ªçƒ
  - è‡ªåŠ¨æ£€æµ‹ç³»ç»Ÿä¸»é¢˜åå¥½
  - ä¸»é¢˜åå¥½æŒä¹…åŒ–åˆ° localStorage
  - å¹³æ»‘çš„é¢œè‰²è¿‡æ¸¡åŠ¨ç”»æ•ˆæœ
- ğŸ¨ **ä¸»é¢˜åˆ‡æ¢æŒ‰é’®** - åœ¨å¯¼èˆªæ æ·»åŠ å¯è§†åŒ–çš„ä¸»é¢˜åˆ‡æ¢æŒ‰é’®
  - æœˆäº®å›¾æ ‡ï¼ˆæµ…è‰²æ¨¡å¼ï¼‰
  - å¤ªé˜³å›¾æ ‡ï¼ˆæ·±è‰²æ¨¡å¼ï¼‰
  - æ”¯æŒé”®ç›˜å¯¼èˆªå’Œå±å¹•é˜…è¯»å™¨
- ğŸ“š **Dark Mode æ–‡æ¡£** - å®Œæ•´çš„ä½¿ç”¨å’Œè‡ªå®šä¹‰æŒ‡å—
  - `docs/cn/features/DARK_MODE_GUIDE.md` - å®Œæ•´æŒ‡å—
  - `docs/cn/features/DARK_MODE_QUICK_REF.md` - å¿«é€Ÿå‚è€ƒ

### Changed
- ğŸ¨ **æ›´æ–°å¸ƒå±€** - `Layout.astro` é›†æˆä¸»é¢˜åˆ‡æ¢åŠŸèƒ½
- ğŸ’… **ä¼˜åŒ– CSS** - æ·»åŠ ä¸»é¢˜åˆ‡æ¢çš„å¹³æ»‘è¿‡æ¸¡æ•ˆæœ
- ğŸ¯ **æ”¹è¿›æ— éšœç¢æ€§** - ä¸»é¢˜åˆ‡æ¢æŒ‰é’®åŒ…å«å®Œæ•´çš„ ARIA æ ‡ç­¾

### Technical Details
- ä½¿ç”¨ React hooks ç®¡ç†ä¸»é¢˜çŠ¶æ€
- CSS å˜é‡å®ç°åŠ¨æ€ä¸»é¢˜åˆ‡æ¢
- æ”¯æŒç³»ç»Ÿä¸»é¢˜åå¥½æ£€æµ‹ (`prefers-color-scheme`)
- localStorage æŒä¹…åŒ–ä¸»é¢˜é€‰æ‹©
- Tailwind CSS `dark:` å˜ä½“æ”¯æŒ

## [1.1.0] - 2025-11-03

### Added
- â˜ï¸ **äº‘ç«¯ LLM æä¾›å•†æ”¯æŒ** - æ–°å¢å¯¹å¤šä¸ªäº‘ç«¯ AI æœåŠ¡çš„é›†æˆ
  - OpenAI (GPT-4, GPT-3.5-turbo, ç­‰)
  - Anthropic Claude (Claude 3 Opus, Sonnet, Haiku)
  - Google Gemini (Gemini Pro, Ultra)
- ğŸ”„ **ç»Ÿä¸€ LLM æ¥å£** - åˆ›å»ºäº†é€šç”¨çš„ LLM æä¾›å•†æ¥å£ (`src/lib/llm-providers.ts`)
- ğŸ¯ **åŠ¨æ€æä¾›å•†åˆ‡æ¢** - API ç«¯ç‚¹æ”¯æŒé€šè¿‡å‚æ•°é€‰æ‹©ä¸åŒçš„ LLM æä¾›å•†
- ğŸ“¡ **æä¾›å•†çŠ¶æ€æŸ¥è¯¢** - æ–°å¢ `/api/chat/providers` ç«¯ç‚¹æŸ¥è¯¢æ‰€æœ‰æä¾›å•†çŠ¶æ€
- ğŸŒŠ **ç»Ÿä¸€æµå¼å“åº”** - æ‰€æœ‰æä¾›å•†éƒ½æ”¯æŒ Server-Sent Events (SSE) æµå¼å“åº”
- ğŸ” **ç¯å¢ƒå˜é‡é…ç½®** - æ‰©å±• `.env.example` åŒ…å«æ‰€æœ‰äº‘ç«¯æä¾›å•†çš„ API Key é…ç½®
- ğŸ“š **å®Œæ•´æ–‡æ¡£** - æ–°å¢äº‘ç«¯ LLM é›†æˆæŒ‡å—å’Œå¿«é€Ÿæµ‹è¯•æ–‡æ¡£
  - `docs/cn/integration/CLOUD_LLM_INTEGRATION.md`
  - `docs/en/integration/CLOUD_LLM_INTEGRATION.en.md`
  - `docs/cn/testing/CLOUD_LLM_QUICK_TEST.md`

### Changed
- â™»ï¸ **é‡æ„è·¯ç”±å¤„ç†** - æ›´æ–° `src/routes/chat.ts` æ”¯æŒå¤šæä¾›å•†æ¶æ„
- ğŸ”§ **æ‰©å±•é…ç½®ç³»ç»Ÿ** - åœ¨ `src/lib/config.ts` ä¸­æ·»åŠ æ‰€æœ‰æä¾›å•†çš„é…ç½®
- ğŸ“ **æ›´æ–° README** - æ·»åŠ äº‘ç«¯ LLM æä¾›å•†ä½¿ç”¨è¯´æ˜

### Technical Details
- ä½¿ç”¨åŸç”Ÿ Fetch API å®ç°æ‰€æœ‰äº‘ç«¯æä¾›å•†é›†æˆï¼Œæ— éœ€é¢å¤– SDK ä¾èµ–
- å®ç°äº† `ILLMProvider` æ¥å£ç¡®ä¿æ‰€æœ‰æä¾›å•†è¡Œä¸ºä¸€è‡´
- æ”¯æŒéæµå¼å’Œæµå¼ä¸¤ç§å“åº”æ¨¡å¼
- å®Œæ•´çš„ç±»å‹å®‰å…¨å’Œé”™è¯¯å¤„ç†

### API Changes
- æ‰€æœ‰èŠå¤© API ç°åœ¨æ¥å— `provider` å‚æ•°æ¥æŒ‡å®š LLM æä¾›å•†
  ```json
  {
    "message": "ä½ çš„æ¶ˆæ¯",
    "provider": "openai|anthropic|google|ollama|openllm",
    "model": "å…·ä½“æ¨¡å‹åç§°"
  }
  ```

## [1.0.0] - 2025-10-10

### Added
- âœ¨ Initial project setup with Astro.js framework
- ğŸ¨ Tailwind CSS integration for modern UI styling
- ğŸ¤– Ollama AI integration for local LLM support
- ğŸ’¬ Real-time chat interface with AI models
- ğŸ“± Responsive design for desktop and mobile devices
- ğŸ›¡ï¸ Complete TypeScript support for type safety
- ğŸ”Œ RESTful API endpoints for chat and model management
- ğŸ“Š Model selection and connection status monitoring
- ğŸš€ Hot reload development environment
- ğŸ“š Comprehensive documentation and setup guide

### Features
- Interactive chat interface with AI models
- Support for multiple Ollama models (llama2, codellama, mistral, etc.)
- Real-time connection status monitoring
- Responsive design with Tailwind CSS
- TypeScript support throughout the project
- Error handling and user feedback
- Clean and modern UI/UX design

### Technical Details
- **Framework**: Astro.js v5.14.3 (Static Site Generator)
- **Styling**: Tailwind CSS v3.4.18 (Utility-first CSS)
- **AI Integration**: Ollama v0.6.0 (Local LLM runtime)
- **Language**: TypeScript (Type-safe development)
- **Build Tool**: Vite (Fast development and building)

### API Endpoints
- `GET /api/models` - Retrieve available Ollama models
- `POST /api/chat` - Send messages to AI models

### Project Structure
```
src/
â”œâ”€â”€ components/Chat.astro    # Main chat interface
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ config.ts           # Application configuration
â”‚   â””â”€â”€ ollama.ts           # Ollama API service layer
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ api/               # REST API endpoints
â”‚   â”œâ”€â”€ index.astro        # Landing page
â”‚   â””â”€â”€ chat.astro         # Chat application page
â””â”€â”€ ...
```

---

## Future Roadmap

### [1.1.0] - Planned
- [ ] ğŸ”„ Streaming responses for real-time AI output
- [ ] ğŸ’¾ Chat history persistence
- [ ] ğŸ¯ Custom model parameters configuration
- [ ] ğŸŒ™ Dark mode toggle
- [ ] ğŸ“¤ Export chat conversations

### [1.2.0] - Planned  
- [ ] ğŸ” User authentication system
- [ ] ğŸ“ File upload and analysis
- [ ] ğŸŒ Multi-language support (i18n)
- [ ] ğŸ“Š Usage analytics dashboard
- [ ] ğŸ¤– Custom AI prompt templates