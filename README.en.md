# ğŸ”¬ Steady Research Pro

<div align="center">

[![License: ISC](https://img.shields.io/badge/License-ISC-blue.svg)](https://opensource.org/licenses/ISC)
[![Node.js Version](https://img.shields.io/badge/node-%3E%3D16-brightgreen)](https://nodejs.org/)
[![Astro](https://img.shields.io/badge/Astro-5.14.8-FF5D01?logo=astro)](https://astro.build/)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](CONTRIBUTING.md)

**An AI-powered research assistant that makes deep research simple and efficient**

English | [ç®€ä½“ä¸­æ–‡](README.md)

[âœ¨ Features](#-features) â€¢ [ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ“– Documentation](#-documentation) â€¢ [ğŸ¤ Contributing](#-contributing)

</div>

---

## ğŸ“– About

Steady Research Pro is a modern intelligent research assistant platform built with **Astro + Tailwind CSS + Ollama**. It combines AI large language models with multi-source information retrieval to provide an all-in-one deep research solution for researchers, students, and content creators.

### ğŸŒŸ Why Choose Steady Research Pro?

- ğŸ¤– **Multiple AI Services** - Support for local Ollama, OpenAI, DeepSeek, Claude, Google Gemini, and more
- ğŸ” **Intelligent Multi-Source Search** - Integrate Bing and Google Search APIs with automatic aggregation and deduplication
- ğŸ“Š **Visual Progress Tracking** - Real-time display of research progress and reasoning traces
- ğŸ¨ **Elegant User Interface** - Modern responsive design based on Tailwind CSS
- ğŸ”„ **Streaming Data Processing** - Support for real-time streaming responses for smooth interactions
- ğŸŒ **Fully Open Source** - ISC license, free to use and modify

## Whatâ€™s Fixed

## ğŸ’¡ Key Advantages

### ğŸ†“ Completely Free
- Open-source code, free to use and modify
- Support for local Ollama models, no API fees
- Optional cloud AI services for flexibility

### ğŸ”’ Privacy & Security
- Local operation mode, data stays on your device
- API keys stored locally
- Full control over data security

### âš¡ High Performance
- Astro static generation for ultra-fast loading
- Streaming responses with real-time feedback
- Optimized search aggregation algorithms

### ğŸ¨ User-Friendly
- Intuitive user interface
- Real-time progress visualization
- Responsive design for all devices

## âœ¨ Features

### Core Capabilities

- ğŸ§  **Intelligent Research Planning** - AI automatically analyzes research topics and generates structured plans
- ğŸ” **Multi-Source Search & Aggregation** - Search multiple engines simultaneously with smart deduplication and ranking
- ğŸ“ˆ **Real-Time Progress Tracking** - Visual display of research stages, progress, and status
- ğŸ”¬ **Reasoning Trace Display** - Transparent view of AI's thought process and reasoning chain
- ğŸ’¬ **Multiple AI Model Support** - Flexible switching between different AI services and models

### Technical Highlights

- âš¡ **Astro Static Generation** - Fast loading with excellent SEO performance
- ğŸ¨ **Tailwind CSS** - Modern responsive UI design
- ğŸ¤– **Ollama Integration** - Support for locally deployed open-source AI models
- ğŸŒŠ **Streaming Responses** - Server-Sent Events for smooth data streaming
- ğŸ“± **Mobile-Friendly** - Fully responsive design for all screen sizes
- ğŸ”’ **Privacy Protection** - Local operation mode keeps data on your device

## ğŸ“ Project Structure

```
Steady-Research-Pro/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/          # Astro components
â”‚   â”‚   â”œâ”€â”€ ResearchAgentUI.astro      # Main research interface
â”‚   â”‚   â”œâ”€â”€ OllamaPanel.astro          # AI service control panel
â”‚   â”‚   â”œâ”€â”€ AIServiceSelector.astro    # AI service selector
â”‚   â”‚   â””â”€â”€ agent/                     # Research agent components
â”‚   â”‚       â”œâ”€â”€ SidePanel.astro        # Configuration sidebar
â”‚   â”‚       â””â”€â”€ ResultsGrid.astro      # Results display grid
â”‚   â”œâ”€â”€ lib/                 # Utility libraries
â”‚   â”‚   â”œâ”€â”€ ollama-client.js           # Ollama client
â”‚   â”‚   â”œâ”€â”€ http-api.js                # HTTP API client
â”‚   â”‚   â”œâ”€â”€ search-api-client.js       # Search API client
â”‚   â”‚   â””â”€â”€ research-processor.js      # Research flow processor
â”‚   â”œâ”€â”€ pages/               # Pages and API routes
â”‚   â”‚   â”œâ”€â”€ index.astro                # Home page
â”‚   â”‚   â””â”€â”€ api/                       # API endpoints
â”‚   â”‚       â”œâ”€â”€ ollama.js              # Ollama API
â”‚   â”‚       â”œâ”€â”€ http-api.js            # HTTP LLM API
â”‚   â”‚       â”œâ”€â”€ research.js            # Research API
â”‚   â”‚       â””â”€â”€ search.js              # Search API
â”‚   â””â”€â”€ styles/
â”‚       â””â”€â”€ global.css                 # Global styles
â”œâ”€â”€ docs/                    # Documentation
â”‚   â”œâ”€â”€ API.md                         # API documentation
â”‚   â””â”€â”€ agents-protocol.md             # Agent protocol docs
â”œâ”€â”€ tests/                   # Test files
â””â”€â”€ public/                  # Static assets
```

## ğŸš€ Quick Start

### Prerequisites

- **Node.js** 16 or higher
- **npm** or **yarn**
- **Ollama** (optional, for local AI models)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/Hastersun/Steady-Research-Pro.git
   cd Steady-Research-Pro
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Start the development server**
   ```bash
   npm run dev
   ```

4. **Open the application**
   
   Visit `http://localhost:4321` in your browser

### Configure AI Services

#### Using Local Ollama (Recommended for beginners)

1. Install [Ollama](https://ollama.ai/)
2. Pull a model: `ollama pull llama2`
3. Start the Ollama service
4. Select "Local Ollama" in the application

#### Using Cloud AI Services

Configure your API keys in the AI service selector:
- OpenAI
- DeepSeek
- Claude (Anthropic)
- Google Gemini

For detailed configuration, see [AI Service Configuration](AI_SERVICE_SELECTOR_README.md)

### Available Commands

```bash
# Build for production
npm run build

# Preview production build
npm run preview

# Run tests
npm test

# Format code
npm run format

# Lint code
npm run lint
```

## ğŸ“– Documentation

- [API Documentation](docs/API.md) - Complete REST API reference
- [AI Service Configuration](AI_SERVICE_SELECTOR_README.md) - Multi-AI service setup guide
- [Search Engine Setup](SEARCH_API_SETUP.md) - Bing and Google Search API configuration
- [Agent Protocol](docs/agents-protocol.md) - Research agent communication protocol

## ğŸ¯ Use Cases

### Target Users

- ğŸ“š **Academic Researchers** - Quickly gather and organize research materials
- âœï¸ **Content Creators** - Deep research for writing materials
- ğŸ‘¨â€ğŸ’¼ **Business Analysts** - Market research and competitor analysis
- ğŸ“ **Students** - Topic research and essay writing
- ğŸ’¡ **Product Managers** - User research and industry trend analysis

### Typical Applications

- Literature reviews for academic papers
- Technology trend research reports
- Market analysis and competitive research
- In-depth news event analysis
- Knowledge base construction and organization

## ğŸ¤ Contributing

We welcome all forms of contributions! Whether it's reporting bugs, suggesting new features, or submitting code improvements.

### How to Contribute

1. Fork this repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

For detailed contribution guidelines, see [CONTRIBUTING.md](CONTRIBUTING.md)

## ğŸ“„ License

This project is licensed under the [ISC License](LICENSE).

## ğŸ™ Acknowledgments

Thanks to the following open-source projects and services:

- [Astro](https://astro.build/) - Modern static site generator
- [Tailwind CSS](https://tailwindcss.com/) - Utility-first CSS framework
- [Ollama](https://ollama.ai/) - Run large language models locally
- [HyperUI](https://www.hyperui.dev/) - Tailwind CSS component library

## ğŸ’¬ Contact & Support

- ğŸ› [Report a Bug](https://github.com/Hastersun/Steady-Research-Pro/issues)
- ğŸ’¡ [Request a Feature](https://github.com/Hastersun/Steady-Research-Pro/issues)
- â­ If this project helps you, please give us a Star!

---

<div align="center">

**If you find this project helpful, please â­Star us!**

Made with â¤ï¸ by [Hastersun](https://github.com/Hastersun)

</div>
